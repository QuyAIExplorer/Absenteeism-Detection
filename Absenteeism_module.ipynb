{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb11b8e9",
   "metadata": {},
   "source": [
    "### Import relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "580160dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41ccae5",
   "metadata": {},
   "source": [
    "### Create our own Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0832b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomScaler(BaseEstimator,TransformerMixin): \n",
    "    \n",
    "    def __init__(self,columns):\n",
    "        self.scaler = StandardScaler()\n",
    "        self.columns = columns\n",
    "        self.mean_ = None\n",
    "        self.var_ = None\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        self.scaler.fit(X[self.columns])\n",
    "        self.mean_ = np.array(np.mean(X[self.columns]))\n",
    "        self.var_ = np.array(np.var(X[self.columns]))\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None, copy=None):\n",
    "        init_col_order = X.columns\n",
    "        X_scaled = pd.DataFrame(self.scaler.transform(X[self.columns]), columns=self.columns)\n",
    "        X_not_scaled = X.loc[:,~X.columns.isin(self.columns)]\n",
    "\n",
    "        return pd.concat([X_not_scaled, X_scaled], axis=1)[init_col_order]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d67bed",
   "metadata": {},
   "source": [
    "### Build absenteeism_module class which has load and clean data function, predict functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfe24e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "class absenteeism_model():\n",
    "    \n",
    "    # Open model and scaler trained\n",
    "    def __init__(self,model_file,scaler_file):\n",
    "        with open('model','rb') as file_model , open('scaler','rb') as file_scaler:\n",
    "            self.reg_model = pickle.load(file_model)\n",
    "            self.reg_scaler = pickle.load(file_scaler)\n",
    "            self.data = None\n",
    "    \n",
    "    # Load and clean data function\n",
    "    def load_and_clean_data(self,data_file):\n",
    "        \n",
    "        # Load data\n",
    "        df = pd.read_csv(data_file)\n",
    "        \n",
    "        # Create a checkpoint with raw_data\n",
    "        self.df_for_predictions = df.copy()\n",
    "        \n",
    "        # drop unnecessary column\n",
    "        df = df.drop(['ID'],axis=1)\n",
    "        \n",
    "        # create dummies \n",
    "        reason_for_absence = pd.get_dummies(df['Reason for Absence'],drop_first=True,dtype=int)\n",
    "        reason_type_A = reason_for_absence.loc[:,0:14].max(axis=1)\n",
    "        reason_type_B = reason_for_absence.loc[:,15:17].max(axis=1)\n",
    "        reason_type_C = reason_for_absence.loc[:,18:21].max(axis=1)\n",
    "        reason_type_D = reason_for_absence.loc[:,22:].max(axis=1)\n",
    "        \n",
    "        # Add 4 types of reason to data\n",
    "        df = pd.concat([df,reason_type_A,reason_type_B,reason_type_C,reason_type_D],axis=1)\n",
    "        \n",
    "        # Drop Reason for Absence\n",
    "        df = df.drop(['Reason for Absence'],axis=1)\n",
    "        \n",
    "        # Change column name\n",
    "        column_names = ['Date', 'Transportation Expense','Distance to Work','Age','Daily Work Load Average','Body Mass Index', 'Education', 'Children', 'Pets','Type_1', 'Type_2', 'Type_3', 'Type_4']\n",
    "        df.columns = column_names\n",
    "        \n",
    "        # Reorder column name\n",
    "        column_names_reordered = ['Type_1', 'Type_2', 'Type_3', 'Type_4','Date', 'Transportation Expense','Distance to Work','Age','Daily Work Load Average','Body Mass Index', 'Education', 'Children', 'Pets']\n",
    "        df = df[column_names_reordered]\n",
    "        \n",
    "        # Convert str date to timestamp\n",
    "        df['Date'] = pd.to_datetime(df['Date'],format='%d/%m/%Y')\n",
    "    \n",
    "        # Extract month of the year\n",
    "        include_month = []\n",
    "        for i in range(df.shape[0]):\n",
    "            include_month.append(df['Date'][i].month)\n",
    "        df['Month'] = include_month\n",
    "        \n",
    "        # Extract weekday of Date column\n",
    "        def extract_weekday(date):\n",
    "            return date.weekday()                      \n",
    "        df['Day of Week'] = df['Date'].apply(extract_weekday)\n",
    "        df = df.drop(['Date'],axis=1)\n",
    "                                    \n",
    "        # Change order of columns \n",
    "        column_names_reordered_1 = ['Type_1', 'Type_2', 'Type_3', 'Type_4','Month', 'Day of Week', 'Transportation Expense',\n",
    "                                   'Distance to Work', 'Age', 'Daily Work Load Average',\n",
    "                                   'Body Mass Index', 'Education', 'Children', 'Pets']\n",
    "        df = df[column_names_reordered_1]\n",
    "                                 \n",
    "        # Get dummies Education\n",
    "        df['Education'] = df['Education'].map({1:0,3:1,2:1,4:1})\n",
    "        \n",
    "        # Process NaN data (if have)\n",
    "        df = df.fillna(value=0)\n",
    "        \n",
    "        # Save if user need to call preprocessed data                   \n",
    "        self.preprocessed_data = df.copy()\n",
    "        \n",
    "        # Scaled data\n",
    "        self.data = self.reg_scaler.transform(df)\n",
    "    \n",
    "    # Predict probability of the result\n",
    "    def predicted_probability(self):\n",
    "        if (self.data is not None):\n",
    "            return self.reg_model.predict_proba(self.data)\n",
    "    \n",
    "    # Predict 1 or 0 category\n",
    "    def predicted_category_output(self):\n",
    "        if (self.data is not None):\n",
    "            return self.reg_model.predict(self.data)\n",
    "    \n",
    "    # Predict all\n",
    "    def predict_outputs_with_inputs(self):\n",
    "        if (self.data is not None):\n",
    "            self.preprocessed_data['Probability'] = self.reg_model.predict_proba(self.data)[:,1]\n",
    "            self.preprocessed_data['Prediction'] = self.reg_model.predict(self.data)\n",
    "            return self.preprocessed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6175c43d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
